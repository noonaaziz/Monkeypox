{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noonaaziz/Monkeypox/blob/main/Monkeypox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yuS1TCHK612"
      },
      "outputs": [],
      "source": [
        "#!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xRaO5ZsabK9",
        "outputId": "c8deaf5b-d6cb-4991-8604-5cf473b66476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.9.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "from distutils.dir_util import copy_tree, remove_tree\n",
        "\n",
        "from PIL import Image\n",
        "from random import randint\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef as MCC\n",
        "from sklearn.metrics import balanced_accuracy_score as BAS\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras import Sequential, Input\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
        "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, MaxPool2D\n",
        "\n",
        "\n",
        "\n",
        "print(\"TensorFlow Version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPtuJmJ1Dgrt",
        "outputId": "513f4ef5-572c-4561-f033-9abe750cf2c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJVzKF94b1Tb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/My Drive/kaggle'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGqoO15Cb3uu",
        "outputId": "1a8742b4-cc7a-4f47-d642-127a2db28e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/kaggle\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTVewUOrcGlH",
        "outputId": "8ec80605-1b70-426f-8e99-8be2cdf82428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/kaggle/api/kaggle_api_extended.py\", line 164, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /content/drive/My Drive/kaggle. Or use the environment method.\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d nafin59/monkeypox-skin-lesion-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6payhtFcLTg",
        "outputId": "e42ba912-3703-4f0c-9c27-11391d263f6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ],
      "source": [
        "!unzip \\*.zip && rm *.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGEcaG9Fc7sr"
      },
      "outputs": [],
      "source": [
        "WORK_DIR = '/content/drive/MyDrive/a'\n",
        "\n",
        "CLASSES = [ 'Monkey Pox',\n",
        "            'Others_augmented']\n",
        "\n",
        "IMG=224\n",
        "\n",
        "IMAGE_SIZE = [224, 224]\n",
        "DIM = (IMG,IMG )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chvo0xFidRQ6"
      },
      "outputs": [],
      "source": [
        "ZOOM = [.99, 1.01]\n",
        "BRIGHT_RANGE = [0.8, 1.2]\n",
        "HORZ_FLIP = True\n",
        "FILL_MODE = \"constant\"\n",
        "DATA_FORMAT = \"channels_last\"\n",
        "\n",
        "work_dr = IDG(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n",
        "\n",
        "train_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=3192, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3ob2h8tdUt8"
      },
      "outputs": [],
      "source": [
        "from random import randint\n",
        "def show_images(generator,y_pred=None):\n",
        "    \"\"\"\n",
        "    Input: An image generator,predicted labels (optional)\n",
        "    Output: Displays a grid of 9 images with lables\n",
        "    \"\"\"\n",
        "\n",
        "    # get image lables\n",
        "    labels =dict(zip([0,1], CLASSES))\n",
        "\n",
        "    # get a batch of images\n",
        "    x,y = generator.next()\n",
        "\n",
        "    # display a grid of 9 images\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    if y_pred is None:\n",
        "        for i in range(9):\n",
        "            ax = plt.subplot(3, 3, i + 1)\n",
        "            idx = randint(0, 3192)\n",
        "            plt.imshow(x[idx])\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(\"Class:{}\".format(labels[np.argmax(y[idx])]))\n",
        "\n",
        "    else:\n",
        "        for i in range(9):\n",
        "            ax = plt.subplot(3, 3, i + 1)\n",
        "            plt.imshow(x[i])\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))\n",
        "\n",
        "# Display Train Images\n",
        "show_images(train_data_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSd7l2ldrZN3"
      },
      "outputs": [],
      "source": [
        "print(CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rvyeYIms_8w"
      },
      "outputs": [],
      "source": [
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMh6Qg7CdwDK"
      },
      "outputs": [],
      "source": [
        "train_data, train_labels = train_data_gen.next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xo5aeK6x6w2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnPzei4ueCPy"
      },
      "outputs": [],
      "source": [
        "print(train_data.shape, train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mJonLGteFfL"
      },
      "outputs": [],
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.1, random_state=42)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDNaXq3meJTx"
      },
      "outputs": [],
      "source": [
        "print(train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpuwThVueVKc"
      },
      "outputs": [],
      "source": [
        "def conv_block(filters, act='relu'):\n",
        "    \"\"\"Defining a Convolutional NN block for a Sequential CNN model. \"\"\"\n",
        "\n",
        "    block = Sequential()\n",
        "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
        "    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n",
        "    block.add(BatchNormalization())\n",
        "    block.add(MaxPool2D())\n",
        "\n",
        "    return block\n",
        "def dense_block(units, dropout_rate, act='relu'):\n",
        "    \"\"\"Defining a Dense NN block for a Sequential CNN model. \"\"\"\n",
        "\n",
        "    block = Sequential()\n",
        "    block.add(Dense(units, activation=act))\n",
        "    block.add(BatchNormalization())\n",
        "    block.add(Dropout(dropout_rate))\n",
        "\n",
        "    return block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDOcJ0xRecAE"
      },
      "outputs": [],
      "source": [
        "def construct_model(act='relu'):\n",
        "    \"\"\"Constructing a Sequential CNN architecture for performing the classification task. \"\"\"\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape=(*IMAGE_SIZE, 3)),\n",
        "        Conv2D(16, 3, activation=act, padding='same'),\n",
        "        Conv2D(16, 3, activation=act, padding='same'),\n",
        "        MaxPool2D(),\n",
        "        conv_block(32),\n",
        "        MaxPool2D(),\n",
        "        conv_block(64),\n",
        "        conv_block(128),\n",
        "        Dropout(0.2),\n",
        "        conv_block(256),\n",
        "        Dropout(0.2),\n",
        "        Flatten(),\n",
        "\n",
        "        dense_block(256, 0.3),\n",
        "        dense_block(128, 0.2),\n",
        "        dense_block(32, 0.2),\n",
        "        Dense(2, activation='sigmoid')\n",
        "    ], name = \"cnn_model\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a7yFlI0ezw_"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons==0.16.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FStQ6QdieipA"
      },
      "outputs": [],
      "source": [
        "#Defining a custom callback function to stop training our model when accuracy goes above 99%\n",
        "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, MaxPool2D\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "\n",
        "#Defining a custom callback function to stop training our model when accuracy goes above 99%\n",
        "\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('val_acc') > 0.99:\n",
        "            print(\"\\nReached accuracy threshold! Terminating training.\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "my_callback = MyCallback()\n",
        "\n",
        "#EarlyStopping callback to make sure model is always learning\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4krkOh4Be7xZ"
      },
      "outputs": [],
      "source": [
        "#Defining other parameters for our CNN model\n",
        "from tensorflow.keras import Sequential, Input\n",
        "\n",
        "model = construct_model()\n",
        "\n",
        "METRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
        "           tf.keras.metrics.AUC(name='auc'),\n",
        "           tfa.metrics.F1Score(num_classes=2)]\n",
        "\n",
        "CALLBACKS = [my_callback]\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.losses.BinaryCrossentropy(),\n",
        "              metrics=METRICS)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PDROISIg7L4"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "history = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS,batch_size=32, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkN8BxYXqVh3"
      },
      "outputs": [],
      "source": [
        "\n",
        "def predict_image(img):\n",
        "  prediction=model.predict(img)\n",
        "  return {CLASSES[i]: float(prediction[i]) for i in range(5)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqUoDexpM7K3"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bQdg0kdqaew"
      },
      "outputs": [],
      "source": [
        "\n",
        "image = gr.inputs.Image(shape=(224,224))\n",
        "label = gr.outputs.Label(num_top_classes=2)\n",
        "\n",
        "gr.Interface(fn=predict_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbG_mNeJrV0m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dsSc-p8lmf4"
      },
      "outputs": [],
      "source": [
        "#Evaluating the model on the data\n",
        "\n",
        "test_scores = model.evaluate(test_data, test_labels)\n",
        "print(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pghL2_TsWNN"
      },
      "outputs": [],
      "source": [
        "pred_labels = model.predict(test_data)\n",
        "#Print the classification report of the tested data\n",
        "\n",
        "#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n",
        "#similar to the test_labels\n",
        "def roundoff(arr):\n",
        "    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n",
        "    arr[np.argwhere(arr != arr.max())] = 0\n",
        "    arr[np.argwhere(arr == arr.max())] = 1\n",
        "    return arr\n",
        "\n",
        "for labels in pred_labels:\n",
        "    labels = roundoff(labels)\n",
        "print(classification_report(test_labels, pred_labels, target_names=CLASSES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78JS6RpMsZf3"
      },
      "outputs": [],
      "source": [
        "#Plot the confusion matrix to understand the classification in detail\n",
        "\n",
        "pred_ls = np.argmax(pred_labels, axis=1)\n",
        "test_ls = np.argmax(test_labels, axis=1)\n",
        "\n",
        "conf_arr = confusion_matrix(test_ls, pred_ls)\n",
        "\n",
        "plt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
        "\n",
        "ax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n",
        "\n",
        "plt.title('Monkeypox detection')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Truth')\n",
        "plt.show(ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K8itlS9sglv"
      },
      "outputs": [],
      "source": [
        "#Printing some other classification metrics\n",
        "\n",
        "print(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\n",
        "print(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiYMqdZcs4Lo"
      },
      "outputs": [],
      "source": [
        "train_scores = model.evaluate(train_data, train_labels)\n",
        "val_scores = model.evaluate(val_data, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4Cdz_XHs_gF"
      },
      "outputs": [],
      "source": [
        "train_scores = model.evaluate(train_data, train_labels)\n",
        "val_scores = model.evaluate(val_data, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI01B6LctFgq"
      },
      "outputs": [],
      "source": [
        "print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n",
        "print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17MbRib_tNPc"
      },
      "outputs": [],
      "source": [
        "#Plotting the trend of the metrics during training\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize = (30, 5))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n",
        "    ax[i].plot(history.history[metric])\n",
        "    ax[i].plot(history.history[\"val_\" + metric])\n",
        "    ax[i].set_title(\"Model {}\".format(metric))\n",
        "    ax[i].set_xlabel(\"Epochs\")\n",
        "    ax[i].set_ylabel(metric)\n",
        "    ax[i].legend([\"train\", \"val\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-C4za9ntWoD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.save('/content/drive/MyDrive/saved model/modelfit.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xetc0YmqFM5q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUeGLkOkFNa9"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Download human-readable labels for ImageNet.\n",
        "response = requests.get(\"https://raw.githubusercontent.com/Fadwahigga/labels/main/classes.txt\")\n",
        "labels = response.text.split(\"\\n\")\n",
        "\n",
        "def classify_image(inp):\n",
        "  inp = inp.reshape((-1, 224, 224, 3))\n",
        "  inp = work_dr(inp)\n",
        "  prediction = model.predict(inp).flatten()\n",
        "  confidences = {CLASSES[i]: float(prediction[i]) for i in range(2)}\n",
        "  return confidences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihy0YRM7GMjR"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "gr.Interface(fn=classify_image,\n",
        "             inputs=gr.Image(shape=(224, 224)),\n",
        "             outputs=gr.Label(num_top_classes=1),\n",
        "             capture_session=True).launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}